[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Posts",
    "section": "",
    "text": "The Art of Readiable R code\n\n\n\n\n\n\n\nLearning Journey\n\n\n\n\n\n\n\n\n\n\n\nAngel Feliz\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Senior Reporting Analyst with 2 years’ experience using R to process and create business reports in formats as Excel, Word, Power Point, and html.\nProven experience integrating ad hoc regular expressions to transform, extract and validate text data in data pipelines to find abnormalities and automate repetitive tasks; improving reporting accuracy, reducing waiting times and opening new possibilities to empower decision makers.\nAutodidactic, self-motivated, inquisitive, and eager to apply data science techniques to create business value and increase ROI for your company"
  },
  {
    "objectID": "posts/01-readiable-code/main.html",
    "href": "posts/01-readiable-code/main.html",
    "title": "The Art of Readiable R code",
    "section": "",
    "text": "Introduction\nWhen we start our journey as a programmers it’s normal to get exited by the new positives. We get the capacity to do many things that otherwise would be impossible, making projects faster and assuring consistency.\nBut the problems start when you need to modify a script that you wrote 6 in the past. That’s when you found out that you don’t remember why you were applying some specific filters or calculating a value in a odd way.\nAs a Reporting Analyst and I am always creating and changing scripts and after applying the tips provided in the book I could reduce the time needed to apply changes from 5 to 2 days (60% faster.)\n\n\n\n1 General qualities of readable code\nBefore giving any trick it is really useful to have a general picture of our code should look like.\n\nCode should be written to minimize the time it would take for someone else to understand it. So nobody should read your code twice to understand what it does.\nHaving explicit names for variables and functions is more important than writing a good comment.\nAfter reading a comment the reader should know as much as the writer did. Not just explaining what the code does, instead explaining reason outside the code."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Characteristics of Successful Protests\n\n\n\n\n\n\n\nData Cleaning\n\n\nText Mining\n\n\n\n\n\n\n\n\n\n\n\nDec 25, 2022\n\n\nAngel Feliz\n\n\n\n\n\n\n  \n\n\n\n\nAdvent Of Code 2022\n\n\n\n\n\n\n\nChallenge\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nAngel Feliz\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html",
    "href": "projs/Advent-Of-Code-2022/main.html",
    "title": "Advent Of Code 2022",
    "section": "",
    "text": "In this post I am sharing my path to complete the 25 days of Advent of Code which is a coding challenge of small programming puzzles.\nLet’s start loading package to use and having fun."
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\ndata.table(Elf = cumsum(!calories %like% \"\\\\d\")+1,\n           Calories = as.integer(calories)\n)[, .(total_calories = sum(Calories, na.rm = TRUE)),\n  by = \"Elf\"\n][, max(total_calories)]\n\n[1] 72478"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\ndata.table(Elf = cumsum(!calories %like% \"\\\\d\")+1,\n           Calories = as.integer(calories)\n)[, .(total_calories = sum(Calories, na.rm = TRUE)),\n  by = \"Elf\"\n][order(-total_calories),\n][1:3\n][, sum(total_calories)]\n\n[1] 210367"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-1",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-1",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nDecryptScore <- \n  c(\"Rock\" = 1, \"Paper\" = 2 , \"Scissors\" = 3)\n\nWin <- \n  c(\"Scissors\" = \"Rock\", \"Rock\" = \"Paper\", \"Paper\" = \"Scissors\")\n\nDecryptCol1 <-\n  c(\"A\" = \"Rock\",  \"B\" = \"Paper\", \"C\" = \"Scissors\")\n\nDecryptCol2 <- \n  c(\"X\" = \"Rock\", \"Y\" = \"Paper\", \"Z\" = \"Scissors\")\n\n\nMyScores <-\n  CJ(col1 = DecryptCol1,\n     col2 = DecryptCol1\n  )[, col2_score := DecryptScore[col2]\n  ][col1 == col2,\n    col2_score := col2_score + 3\n  ][Win[col1] == col2,\n    col2_score := col2_score + 6]\n\n\ncopy(EncryptedGuide)[, `:=`(col1 = DecryptCol1[col1],\n                            col2 = DecryptCol2[col2])\n][MyScores, on = c(\"col1\",\"col2\"), nomatch = 0\n][, sum(col2_score)]\n\n[1] 13005"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-1",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-1",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nLose <- names(Win)\nnames(Lose) <- Win\n\ncopy(EncryptedGuide)[, `:=`(col1 = DecryptCol1[col1],\n                            col2 = fcase(col2 == \"X\",\n                                         Lose[DecryptCol1[col1]],\n                                         col2 == \"Y\",\n                                         DecryptCol1[col1],\n                                         col2 == \"Z\",\n                                         Win[DecryptCol1[col1]]))\n                     \n][MyScores, on = c(\"col1\",\"col2\"), nomatch = 0\n][, sum(col2_score)]\n\n[1] 11373"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-2",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-2",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nRucksackItems[, .(id = .I,\n                  sack1 = substr(items, 1, nchar(items)/2) ,\n                  sack2 = substr(items, nchar(items)/2 +1, nchar(items)) )\n][, .(sack1 = strsplit(sack1,\"\"),\n      sack2 = strsplit(sack2,\"\")),\n  by = \"id\"\n][, merge(copy(.SD)[, .(sack1 = sack1[[1]]), \"id\"],\n          copy(.SD)[, .(sack2 = sack2[[1]]), \"id\"],\n          by = \"id\", allow.cartesian=TRUE)\n][sack1 == sack2,\n  unique(.SD)\n][, priority := which(sack1 == c(letters,LETTERS)),\n  by = \"id\"\n][, sum(priority)]\n\n[1] 7878"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-2",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-2",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nRucksackItems[, .(id = .I,\n                  group = cumsum(.I %% 3 == 1),\n                  items = strsplit(items,\"\") )\n][, .(items = items[[1]]),\n  by = c(\"group\",\"id\")\n][, .(n_id = uniqueN(id)),\n  by = c(\"items\",\"group\")\n][n_id == 3\n][, priority := which(items == c(letters,LETTERS)),\n  by = \"group\"\n][, sum(priority)]\n\n[1] 2760"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-3",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-3",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nCleanupPlan[, c(\"range1_start\",\"range1_end\",\n                \"range2_start\",\"range2_end\") := \n         tstrsplit(pair, \",|-\") |> lapply(as.integer)\n][ (range1_start >=  range2_start & range1_end <= range2_end) |\n   (range2_start >=  range1_start & range2_end <= range1_end),\n   .N]\n\n[1] 511"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-3",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-3",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nCleanupPlan[, c(\"range1_start\",\"range1_end\",\n                \"range2_start\",\"range2_end\") := \n         tstrsplit(pair, \",|-\") |> lapply(as.integer)\n][, n_intersect := \n    intersect(range1_start:range1_end,\n              range2_start:range2_end) |>\n    length(),\n  by = .I\n][n_intersect > 0, .N]\n\n[1] 821"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-4",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-4",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nMovedStacks <-\n  copy(StartingStacks)\n\nfor(move_i in seq_len(nrow(Movements))){\n  \n  n_items <- Movements[move_i, n_items]\n  from <- Movements[move_i, from]\n  to <- Movements[move_i, to]\n  \n  MovedStacks[, (to) := .(c(get(from)[[1]][n_items:1], get(to)[[1]]))]\n  MovedStacks[, (from) := .(get(from)[[1]][-(n_items:1)])]\n  \n}\n\nsapply(MovedStacks,\\(x) x[[1]][1]) |>\n  paste0(collapse = \"\")\n\n[1] \"HNSNMTLHQ\""
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-4",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-4",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nMovedStacks <-\n  copy(StartingStacks)\n\nfor(move_i in seq_len(nrow(Movements))){\n  \n  n_items <- Movements[move_i, n_items]\n  from <- Movements[move_i, from]\n  to <- Movements[move_i, to]\n  \n  MovedStacks[, (to) := .(c(get(from)[[1]][1:n_items], get(to)[[1]]))]\n  MovedStacks[, (from) := .(get(from)[[1]][-(1:n_items)])]\n  \n}\n\nsapply(MovedStacks,\\(x) x[[1]][1]) |>\n  paste0(collapse = \"\")\n\n[1] \"RNLFDJMCT\""
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-5",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-5",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nUniqueLetters <- 4\n\ncopy(DataStream)[, data := gsub(\"\",\" \", data)\n][, tidytext::unnest_ngrams(.SD, letter, data, n = UniqueLetters)\n][, n_unique := strsplit(letter,\" \") |> unlist() |> uniqueN(),\n  by = .I\n][, n_letter := (1:.N) - 1 + UniqueLetters,\n  by = \"id\"\n][n_unique == UniqueLetters, \n  unique(.SD, by = \"id\")]\n\n      id  letter n_unique n_letter\n   <int>  <char>    <int>    <num>\n1:     1 v h p j        4     1804"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-5",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-5",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nUniqueLetters <- 14\n\ncopy(DataStream)[, data := gsub(\"\",\" \", data)\n][, tidytext::unnest_ngrams(.SD, letter, data, n = UniqueLetters)\n][, n_unique := strsplit(letter,\" \") |> unlist() |> uniqueN(),\n  by = .I\n][, n_letter := (1:.N) - 1 + UniqueLetters,\n  by = \"id\"\n][n_unique == UniqueLetters, \n  unique(.SD, by = \"id\")]\n\n      id                      letter n_unique n_letter\n   <int>                      <char>    <int>    <num>\n1:     1 r n f g h s v p c w j d t l       14     2508"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-6",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-6",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nDirSizes[size < 100000,\n         sum(size)]\n\n[1] 1611443"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-6",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-6",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nDirSizes[size > 30000000 - (70000000 - DirSizes[all_dirs == \"/\", size]),\n         min(size)]\n\n[1] 2086088"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-7",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-7",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nInvibleCheck <-         \n                        # Checking the matrix going back \n  TidyInTreeGrid[, `:=`(top_invisible = \n                          sum(in_value <= \n                                TreeGrid[(row-1):1, col]),\n                        left_invisble = \n                          sum(in_value <= \n                                TreeGrid[row, (col-1):1]),\n                        \n                        # Checking the matrix going forward\n                        botton_invisible = \n                          sum(in_value <= \n                                TreeGrid[(row+1):DimGrid[1], col]),\n                        right_invisible = \n                          sum(in_value <= \n                                TreeGrid[row, (col+1):DimGrid[2]])),\n                 by = .I\n  ][, invisible_tree := \n      top_invisible > 0 & botton_invisible > 0 & \n      right_invisible > 0 & left_invisble > 0]\n\nprod(DimGrid) - sum(InvibleCheck$invisible_tree)\n\n[1] 1792"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-7",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-7",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nsum_distance <- function(x){\n  if(any(x)){\n    return(seq_along(x)[cumsum(x) == 1] |> min())\n  }\n  return(length(x))\n}\n\n\nDistanceCheck <-\n                        # Checking the matrix going back\n  TidyInTreeGrid[, `:=`(top_distance = \n                          sum_distance(in_value <= \n                                         TreeGrid[(row-1):1, col]),\n                        left_distance = \n                          sum_distance(in_value <= \n                                         TreeGrid[row, (col-1):1]),\n                        \n                        # Checking the matrix going forward\n                        botton_distance = \n                          sum_distance(in_value <= \n                                         TreeGrid[(row+1):DimGrid[1], col]),\n                        right_distance = \n                          sum_distance(in_value <= \n                                         TreeGrid[row, (col+1):DimGrid[2]])),\n                 by = .I\n  ][, scenic_score := \n      top_distance * botton_distance * \n      right_distance  * left_distance]\n\nDistanceCheck[, max(scenic_score)]\n\n[1] 334880"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-8",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-8",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nsimulate_move <- function(DT,\n                          y_H_pos,\n                          x_H_pos,\n                          T_number){\n  \n    DT[,`:=`(y_H_pos = y_H,\n             x_H_pos = x_H,\n             y_T_old_pos = c(0,rep(NA_real_,.N-1)),\n             x_T_old_pos = c(0,rep(NA_real_,.N-1)),\n             y_T_new_pos = NA_real_,\n             x_T_new_pos = NA_real_),\n       env = list(y_H = y_H_pos,\n                  x_H = x_H_pos)]\n  \n  RowsToWalk <- nrow(DT) |> seq_len()\n  \n  for(i in RowsToWalk){\n\n    x_T_old <- DT$x_T_old_pos[i]\n    y_T_old <- DT$y_T_old_pos[i]\n    \n    distance <- c(x = DT$x_H_pos[i] - x_T_old,\n                  y = DT$y_H_pos[i] - y_T_old)\n    \n    # Don't move\n    if(all(abs(distance) <= 1)){\n      set(DT,i,\"y_T_new_pos\",y_T_old)\n      set(DT,i,\"x_T_new_pos\",x_T_old)\n      \n      # Move TR  \n    }else if(distance[\"x\"] >= 1 && distance[\"y\"] >= 1){\n      set(DT,i,\"y_T_new_pos\",y_T_old + 1)\n      set(DT,i,\"x_T_new_pos\",x_T_old + 1)  \n      \n      # Move BR  \n    }else if(distance[\"x\"] >= 1 && distance[\"y\"] <= -1){\n      set(DT,i,\"y_T_new_pos\",y_T_old - 1)\n      set(DT,i,\"x_T_new_pos\",x_T_old + 1)  \n      \n      # Move TL  \n    }else if(distance[\"x\"] <= -1 && distance[\"y\"] >= 1){\n      set(DT,i,\"y_T_new_pos\",y_T_old + 1)\n      set(DT,i,\"x_T_new_pos\",x_T_old - 1)\n      \n      # Move BL  \n    }else if(distance[\"x\"] <= -1 && distance[\"y\"] <= -1){\n      set(DT,i,\"y_T_new_pos\",y_T_old - 1)\n      set(DT,i,\"x_T_new_pos\",x_T_old - 1) \n      \n      # Move to R\n    }else if(distance[\"x\"] == 2){\n      set(DT,i,\"y_T_new_pos\",y_T_old)\n      set(DT,i,\"x_T_new_pos\",x_T_old + 1)\n      \n      # Move to L\n    }else if(distance[\"x\"] == -2){\n      set(DT,i,\"y_T_new_pos\",y_T_old)\n      set(DT,i,\"x_T_new_pos\",x_T_old - 1)\n      \n      # Move to T  \n    }else if(distance[\"y\"] == 2){\n      set(DT,i,\"y_T_new_pos\",y_T_old + 1)\n      set(DT,i,\"x_T_new_pos\",x_T_old)\n      \n      # Move to B  \n    }else if(distance[\"y\"] == -2){\n      set(DT,i,\"y_T_new_pos\",y_T_old - 1)\n      set(DT,i,\"x_T_new_pos\",x_T_old)\n    }\n    \n    \n    # Moving the new position to be old one in next row\n    if(i < RowsToWalk[length(RowsToWalk)]){\n      set(DT,i+1L,\"y_T_old_pos\",DT$y_T_new_pos[i])\n      set(DT,i+1L,\"x_T_old_pos\",DT$x_T_new_pos[i])\n    }\n    \n  }\n  \n  DT[, c(\"y_H_pos\", \"x_H_pos\", \"y_T_old_pos\", \"x_T_old_pos\") := NULL]\n  \n  setnames(DT, c(\"y_T_new_pos\", \"x_T_new_pos\"),\n           paste0(c(\"y_\",\"x_\"), T_number, \"_new_pos\"))\n  \n  return(DT)\n  \n}\n\n\nBaseTable1 <- copy(RopeBridge)\n\nsimulate_move(BaseTable1,\n              y_H_pos = \"y_H_position\",\n              x_H_pos = \"x_H_position\",\n              T_number = \"T\")\n\n\nBaseTable1[, unique(.SD), .SDcols = c(\"x_T_new_pos\",\"y_T_new_pos\")][, .N]\n\n[1] 5883"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-8",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-8",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nBaseTable2 <- copy(RopeBridge)\n\nIteration <-\n  lapply(1:8,\\(x) c(str_glue(\"y_{x}_new_pos\"), str_glue(\"x_{x}_new_pos\"), x+1)) |>\n  (\\(LIST) append(list(c(\"y_H_position\",\"x_H_position\",\"1\")),\n                  LIST))()\n\n\nfor(i in seq_along(Iteration)){\n  \n  simulate_move(BaseTable2,\n                y_H_pos = Iteration[[i]][1],\n                x_H_pos = Iteration[[i]][2],\n                T_number = Iteration[[i]][3])\n  \n}\n\nBaseTable2[, unique(.SD), .SDcols = c(\"x_9_new_pos\",\"y_9_new_pos\")][, .N]\n\n[1] 2367"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-9",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-9",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1\n\nClockCircuit[seq(from = 20, to = 220, by =40),\n             sum(signal_strength)]\n\n[1] 11720"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-9",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-9",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2\n\nClockCircuit[,`:=`(row = (cycle-1) %/% 40,\n                   col = (cycle-1) %% 40)\n][, pixel := fifelse(abs(col-X)<=1, \"#\",\".\")\n][, paste0(pixel,collapse = \"\"),\n  by = \"row\"]\n\n     row                                       V1\n   <num>                                   <char>\n1:     0 ####.###...##..###..####.###...##....##.\n2:     1 #....#..#.#..#.#..#.#....#..#.#..#....#.\n3:     2 ###..#..#.#....#..#.###..#..#.#.......#.\n4:     3 #....###..#....###..#....###..#.......#.\n5:     4 #....#.#..#..#.#.#..#....#....#..#.#..#.\n6:     5 ####.#..#..##..#..#.####.#.....##...##.."
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-10",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-10",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-10",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-10",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-11",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-11",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-11",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-11",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-12",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-12",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-12",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-12",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-13",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-13",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-13",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-13",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-14",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-14",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-14",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-14",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-15",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-15",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-15",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-15",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-16",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-16",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-16",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-16",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-17",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-17",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-17",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-17",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-18",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-18",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-18",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-18",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-19",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-19",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-19",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-19",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-20",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-20",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-20",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-20",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-21",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-21",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-21",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-21",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-22",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-22",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-22",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-22",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-23",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-23",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-23",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-23",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-1-24",
    "href": "projs/Advent-Of-Code-2022/main.html#part-1-24",
    "title": "Advent Of Code 2022",
    "section": "Part 1",
    "text": "Part 1"
  },
  {
    "objectID": "projs/Advent-Of-Code-2022/main.html#part-2-24",
    "href": "projs/Advent-Of-Code-2022/main.html#part-2-24",
    "title": "Advent Of Code 2022",
    "section": "Part 2",
    "text": "Part 2"
  },
  {
    "objectID": "projs/mass-protest-data/main.html",
    "href": "projs/mass-protest-data/main.html",
    "title": "Characteristics of Successful Protests",
    "section": "",
    "text": "Protests are an important part of society change. In this time we are going to explore data from The Mass Mobilization Project which contains information about protests against governments, and contains a variety of variables such as location, dates and number of participants. The data is available in the Mass Protest Data Data Camp Github folder.\nThe goal of this project is to define what characteristics share successful protests worldwide. The first step to achieve that it is to define what do I mean with successful. As most the protests demand state actions I consider that a protest is successful when there is a reconciliation between the two parts.\n\nTo make that possible we will apply the next skills during the process:\n\nFunctional programming with R\nData manipulation with data.table, lubridate and stringr\nText mining with tidytext\nData visualization with ggplot2, scales, forcats and patchwork\nNetwork visualization with igraph and ggraph\nAutomated reporting with quarto, flextable, html and css\n\nThe source code of this project is available on Github."
  },
  {
    "objectID": "projs/mass-protest-data/main.html#libraries-importantion",
    "href": "projs/mass-protest-data/main.html#libraries-importantion",
    "title": "Characteristics of Successful Protests",
    "section": "1.1 Libraries importantion",
    "text": "1.1 Libraries importantion\nLibraries are very useful, but they can change over time making that the code used today might not work tomorrow. So, the first step before loading the libraries is to save a file (renv.lock) with all R package dependencies and the next code line we validate if we are tuning the project using the same version of package.\n\n#| echo: false\n#| include: false\n\nif (!requireNamespace(\"renv\", quietly = TRUE)) install.packages(\"renv\")\nrenv::restore()\n\n* The library is already synchronized with the lockfile.\n\n\nNow we can load the libraries to use. To avoid unnecessary conflict if we just need a function from a library we copy the function in the global environment by using the syntax PackageName::FunctionName.\n\nlibrary(data.table)\nlibrary(lubridate)\nlibrary(stringr)\n\nlibrary(flextable)\n\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(forcats)\nlibrary(igraph)\nlibrary(ggraph)\n\nlibrary(tidytext)\n\nglimpse <- pillar::glimpse\ncodelist_panel <- countrycode::codelist_panel\ncorrelation <- correlation::correlation\nhere <- here::here"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#custom-functions",
    "href": "projs/mass-protest-data/main.html#custom-functions",
    "title": "Characteristics of Successful Protests",
    "section": "1.2 Custom functions",
    "text": "1.2 Custom functions\nOpen-source packages are very powerful as they provide general purpose functions, but it’s also useful to have some custom project functions to perform repetitive task and improve code readability. During this project, we will use the following functions group it purpose:\n\n1.2.1 Styling\n\ncustom_theme: Defines the style of all ggplots across the project.\n\n\nCustomTheme <-\ntheme_light()+\n  theme(axis.text = element_text(size = 15),\n        axis.title = element_text(size = 16, face = \"bold\"),\n        strip.text = element_text(size = 16, face = \"bold\"),\n        plot.title = element_text(size = 25, face = \"bold\", \n                                  hjust = 0.5, margin = margin(b = 15)),\n        \n        legend.title = element_text(size = 15, face = \"bold\"),\n        legend.text = element_text(size = 14))\n\ntheme_set(CustomTheme)\nrm(CustomTheme)\n\n\nstyle_table: Takes a data.frame and renders it as html table with a custom style.\n\n\nstyle_table <- function(DF){\n  \n  flextable(DF) |>\n  theme_vanilla() |>\n  autofit()\n  \n}\n\n\n\n1.2.2 Data cleaning\n\nlower_clean_name: Lower the case all words in a vector and remove any character that isn’t a word.\n\n\nlower_clean_name <- function(text){\n  \n  str_to_lower(text) |>\n    str_replace_all(\"[^A-Za-z ']\",\" \") |> \n    str_squish()\n}\n\n\nclean_amount: Transforms a character vector with number and commas into a double one.\n\n\nclean_amount <- \\(x) gsub(\",\",\"\",x) |> as.double()\n\n\n\n1.2.3 Data transformation\n\nfind_string_approximation: This function merges two data.tables to generate all possible combinations between them and select for each id the match that minimize the string distance between words of both tables. This function was inspired by the reclin2 package as both follow simular steps.\n\n\nfind_string_approximation <- function(DT1,\n                                      DT2,\n                                      id.var,\n                                      merge.by,\n                                      match.vars,\n                                      min.tolerance = 0.7,\n                                      stringdist.method = \"lcs\"){\n  \n  merge(DT1, DT2, by = merge.by, allow.cartesian = TRUE\n  )[, weight := 1 - stringdist::stringdist(get(match.vars[1]),get(match.vars[2]), \n                                           method = stringdist.method) /\n                    (nchar(get(match.vars[1]))+nchar(get(match.vars[2])))\n  ][weight >= min.tolerance\n  ][order(-weight),\n    unique(.SD, by = id.var)]\n  \n}\n\n\n\n1.2.4 Plotting\n\nplot_word_found_distribution: Creates a plot to show how the found words are distributed acording the number of words that have the word.count.var.\n\n\nplot_word_found_distribution <- function(DT,\n                                         word.count.var,\n                                         prostest.id.found,\n                                         success.label,\n                                         no.found.label,\n                                         label.colors,\n                                         title = \"Number of words distribution\",\n                                         subtitle = \"\",\n                                         x.lab = \"Number of words\", \n                                         y.lab = \"\"){\n  \n  DT[!is.na(get(word.count.var)),\n     .(id,\n       word_count =  str_count(get(word.count.var),\" \")+1,\n       success = fifelse(id %in% prostest.id.found,\n                         success.label,\n                         no.found.label) |> \n                 factor(levels = names(label.colors)[c(2,1)] ))] |>\n    ggplot(aes(x = word_count,y = success, color = success))+\n    geom_jitter(alpha = 0.20, size = 2, height = 0.40, width = 0.15)+\n    scale_x_continuous(breaks = breaks_width(1,1))+\n    scale_color_manual(values = label.colors)+\n    labs(title = title, subtitle = subtitle, x = x.lab, y = y.lab)+\n    theme(plot.subtitle = element_text(size = 18, margin = margin(b = 15)),\n          panel.grid.major.y = element_blank(),\n          legend.position = \"none\")\n  \n}"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#data-importation",
    "href": "projs/mass-protest-data/main.html#data-importation",
    "title": "Characteristics of Successful Protests",
    "section": "1.3 Data importation",
    "text": "1.3 Data importation\nIn this section we will take the data available and load it into R as data.table objects.\n\n1.3.1 Main data\nProtestRaw will be the main reference to use during the analysis. Any other imported data during this project will be used to extend or clean the information given in this data.\n\nProtestRaw <-\n  fread(here(\"Raw-data/protest_data.csv\"), \n        na.strings = \"\", integer64 = \"double\")\n\nglimpse(ProtestRaw)\n\nRows: 17,145\nColumns: 31\n$ id                    <dbl> 201990001, 201990002, 201990003, 201990004, 2019…\n$ country               <chr> \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\"…\n$ ccode                 <int> 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, …\n$ year                  <int> 1990, 1990, 1990, 1990, 1990, 1990, 1991, 1991, …\n$ region                <chr> \"North America\", \"North America\", \"North America…\n$ protest               <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ protestnumber         <int> 1, 2, 3, 4, 5, 6, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, …\n$ startday              <int> 15, 25, 1, 12, 14, 19, 10, 28, 4, 16, 1, 1, 18, …\n$ startmonth            <int> 1, 6, 7, 7, 8, 9, 9, 9, 5, 5, 7, 9, 11, 2, 9, 10…\n$ startyear             <int> 1990, 1990, 1990, 1990, 1990, 1990, 1991, 1991, …\n$ endday                <int> 15, 25, 1, 6, 15, 19, 17, 2, 5, 16, 31, 1, 18, 2…\n$ endmonth              <int> 1, 6, 7, 9, 8, 9, 9, 10, 5, 5, 8, 9, 11, 2, 9, 1…\n$ endyear               <int> 1990, 1990, 1990, 1990, 1990, 1990, 1991, 1991, …\n$ protesterviolence     <int> 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, …\n$ location              <chr> \"national\", \"Montreal, Quebec\", \"Montreal, Quebe…\n$ participants_category <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ participants          <chr> \"1000s\", \"1000\", \"500\", \"100s\", \"950\", \"200\", \"1…\n$ protesteridentity     <chr> \"unspecified\", \"unspecified\", \"separatist parti …\n$ protesterdemand1      <chr> \"political behavior, process\", \"political behavi…\n$ protesterdemand2      <chr> \"labor wage dispute\", NA, NA, NA, NA, NA, NA, NA…\n$ protesterdemand3      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ protesterdemand4      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ stateresponse1        <chr> \"ignore\", \"ignore\", \"ignore\", \"accomodation\", \"c…\n$ stateresponse2        <chr> NA, NA, NA, NA, \"arrests\", \"shootings\", NA, NA, …\n$ stateresponse3        <chr> NA, NA, NA, NA, \"accomodation\", NA, NA, NA, NA, …\n$ stateresponse4        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ stateresponse5        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ stateresponse6        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ stateresponse7        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sources               <chr> \"1. great canadian train journeys into history; …\n$ notes                 <chr> \"canada s railway passenger system was finally c…\n\n\n\n\n1.3.2 Complementary data\nLet’s import complementary data to make sense, clean and expand the information provided in ProtestRaw.\n\nWorldCities: It has information about 239 countries and their cities. It will be used to clean the location field in the main data. The data can be found in Simple Maps as a free database.\n\n\nWorldCities <-\n  fread(here(\"Raw-data/worldcities.csv\"), na.strings = \"\", sep=\",\",\n        select = c(\"country\",\"city_ascii\",\"capital\",\"population\")\n  )[order(country,-population)\n    \n  # Applying some manual modifications to assure that ProtestRaw and WorlCites\n  # use the same name for the same country\n  ][,`:=`(country = fcase(country == \"Hong Kong\",\"China\",\n                          country == \"The Gambia\",\"Gambia\",\n                          country == \"United Arab Emirates\",\"United Arab Emirate\",\n                          country == \"Cabo Verde\", \"Cape Verde\",\n                          country == \"Bosnia And Herzegovina\",\"Bosnia\",\n                          country == \"Slovakia\", \"Slovak Republic\",\n                          country == \"Czechia\",\"Czech Republic\",\n                          rep(TRUE,.N), country) |>\n                   lower_clean_name(),\n          city_ascii = lower_clean_name(city_ascii))\n   \n  # Identifying the capital of each country in each raw\n  ][!capital %like% \"\\\\w\", \n    capital := NA_character_\n  ][country == \"taiwan\" & city_ascii == \"taipei\", \n    capital := \"primary\"]\n\nglimpse(WorldCities)\n\nRows: 42,905\nColumns: 4\n$ country    <chr> \"afghanistan\", \"afghanistan\", \"afghanistan\", \"afghanistan\",…\n$ city_ascii <chr> \"kabul\", \"kandahar\", \"herat\", \"mazar e sharif\", \"taluqan\", …\n$ capital    <chr> \"primary\", \"admin\", \"admin\", \"admin\", \"admin\", \"admin\", \"ad…\n$ population <dbl> 4273156, 614254, 556205, 469247, 263800, 263312, 259809, 20…\n\n\n\nCountryCode: It has information of country codes from many institutions and we will use it to find out the ccode origin. It comes from the countrycode R package in the version 1.4.1.\n\n\nCountryCode <-\n  codelist_panel |>\n  as.data.table() |>\n  (\\(DT) DT[year >= min(ProtestRaw$year), \n            .SD, \n            .SDcols= c(\"country.name.en\",\n                       \"country.name.en.regex\",\n                       names(DT)[sapply(DT, is.double)])\n         \n          # Germany, West correction from Raw-data/p5manualv2018.pdf\n         ][country.name.en == \"Germany\" & year == 1990,\n           c(\"p4n\",\"p5n\") := 260] )()\n\nglimpse(CountryCode)\n\nRows: 6,301\nColumns: 19\n$ country.name.en            <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\"…\n$ country.name.en.regex      <chr> \"afghan\", \"afghan\", \"afghan\", \"afghan\", \"af…\n$ year                       <dbl> 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1…\n$ cown                       <dbl> 700, 700, 700, 700, 700, 700, 700, 700, 700…\n$ fao                        <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ gaul                       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ gwn                        <dbl> 700, 700, 700, 700, 700, 700, 700, 700, 700…\n$ imf                        <dbl> 512, 512, 512, 512, 512, 512, 512, 512, 512…\n$ iso3n                      <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ iso4217n                   <dbl> 971, 971, 971, 971, 971, 971, 971, 971, 971…\n$ p4n                        <dbl> 700, 700, 700, 700, 700, 700, 700, 700, 700…\n$ p5n                        <dbl> 700, 700, 700, 700, 700, 700, 700, 700, 700…\n$ un                         <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ un.region.code             <dbl> 142, 142, 142, 142, 142, 142, 142, 142, 142…\n$ un.regionintermediate.code <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ un.regionsub.code          <dbl> 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,…\n$ unpd                       <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ vdem                       <dbl> 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,…\n$ wvs                        <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n\n\n\nPolity5: Has some indicators to describe how state structures have been changing overtime. According with\n\nDEMOC: Goes from 0 to 10 to measure democracy level in a country in a specific time.\nAUTOC: Goes from 0 to 10 to measure autocracy level in a country in a specific time.\nPOLITY: Results from the operation of subtracting AUTOC from DEMOC measure, to provide a single regime score that ranges from +10 (full democracy) to -10 (full autocracy).\nDURABLE: Saves the number of years since the last substantive change in authority characteristics (defined as a 3-point change in the POLITY score).\n\n\nThis data comes from the Polity5 Annual Time-Series, 1946-2018 Excel report.\n\nPolity5 <-\n  \n  fread(here(\"Raw-data/Polity5.csv\"), na.strings = \"\",\n        select = c(\"ccode\" = \"integer\",\n                   \"year\" = \"integer\",\n                   \"democ\" = \"double\",\n                   \"autoc\" = \"double\",\n                   \"polity\" = \"double\",\n                   \"durable\" = \"integer\")\n  \n  # According to the users’ manual polity \n  # values out of [-10,10] have a special meaning\n  )[, government_status := fcase(polity == -66, \"Interruption\",\n                                polity == -77, \"Interregnum\",\n                                polity == -88, \"Transition\",\n                                default = \"Active\")\n  ][government_status != \"Active\", \n    c(\"democ\",\"autoc\",\"polity\") := NA_real_]\n\n\nglimpse(Polity5)\n\nRows: 17,574\nColumns: 7\n$ ccode             <int> 700, 700, 700, 700, 700, 700, 700, 700, 700, 700, 70…\n$ year              <int> 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808…\n$ democ             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ autoc             <dbl> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7…\n$ polity            <dbl> -6, -6, -6, -6, -6, -6, -6, -6, -6, -6, -6, -6, -6, …\n$ durable           <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ government_status <chr> \"Active\", \"Active\", \"Active\", \"Active\", \"Active\", \"A…"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#validation-process",
    "href": "projs/mass-protest-data/main.html#validation-process",
    "title": "Characteristics of Successful Protests",
    "section": "2.1 Validation process",
    "text": "2.1 Validation process\nOnce we have all the data in R we can start to check the information that contains each column of ProtestRaw, as there is no documentation related to the main data we need to check if the columns really have what we think after reading each title:\n\nid shares an unique number for each row. And we see the test bellow.\n\n\nProtestRaw[, .(`Number of Rows` = .N,\n               `Number of Ids` = uniqueN(id))] |>\n  style_table()\n\n\n\nNumber of RowsNumber of Ids17,14517,145\n\n\n\ncountry stores the names of countries where each protest happened. This dataset has information about 166 countries.\n\n\nProtestRaw[,.(`Number of Countries` = uniqueN(country))] |>\n  style_table()\n\n\n\nNumber of Countries166\n\n\n\nccode provides a code reference for each country. By making a simple check we can confirm that a country can have more than one code depending of the protest year, as we can see bellow.\n\n\nProtestRaw[order(year), \n           .(ccode, year, n_country_ccode = uniqueN(ccode)),\n           by = \"country\"\n][n_country_ccode > 1, \n  unique(.SD,by = \"ccode\"),\n  .SDcols = c(\"country\",\"ccode\",\"year\")] |>\n  style_table()\n\n\n\ncountryccodeyearYugoslavia3451,990Yugoslavia3471,992Ethiopia5301,990Ethiopia5292,016Yemen6791,990Yemen6782,016\n\n\nAs we don’t know which rule is following the code let’s use the data provided by the countrycode package to find out the ccode source. To make data that we need to perform a join operation in two parts by starting with countries that have the same name and year in both data frames.\n\nCountryCodeExactMatch <-\n  CountryCode[ProtestRaw[, unique(.SD), \n                         .SDcols = c(\"country\",\"ccode\",\"year\")],\n                on = c(\"country.name.en\" = \"country\", \"year\"),\n                nomatch = 0]\n\nTo perform the join operation with the missing countries we need to apply a more complex approach by applying the following steps :\n\nSelecting the countries that wasn’t found using a exact match\nCreating a table with all possible combinations between missing countries and regular expressions provided by countrycode package\nSelecting rows that match the regular expression\nAdding possible country codes and years by regular expression\nSelecting rows with the same country and year as ProtestRaw\n\n\nCountryCodeRegexMatch <-\n  \n    # Selecting the countries that wasn't found using a exact match\n    ProtestRaw[! country %chin% CountryCodeExactMatch$country.name.en, \n               .(country = unique(country))\n\n    # Creating country and regex combinations\n    ][, CJ(country = country,\n           country.name.en.regex = CountryCode$country.name.en.regex,\n           unique = TRUE)\n      \n    # Selecting regex that match with countries' names\n    ][, match_text := str_detect(str_to_lower(country), country.name.en.regex),\n      by = .I\n    ][match_text == TRUE,\n      unique(.SD, by = \"country\"),\n      .SDcols = c(\"country\", \"country.name.en.regex\")\n\n    # Adding possible country codes and years by regular expression\n    ][CountryCode, on = \"country.name.en.regex\", nomatch = 0\n\n    # Selecting rows with the same country and year as ProtestRaw\n    ][ProtestRaw[, unique(.SD), .SDcols = c(\"country\",\"ccode\",\"year\")],\n      on = c(\"country\", \"year\"), nomatch = 0\n    ][, `:=`(country.name.en = country,\n             country = NULL)]\n\nAfter applying all this steps we just need to bind both data frames and confirm if we found all possible country codes for every country listed in ProtestRaw.\n\nCountryCodeConsolidated <-\n  rbind(CountryCodeExactMatch,\n        CountryCodeRegexMatch)\n\n# Checking it was any country and year that wasn't found\nProtestRaw[, c(\"country\",\"year\")\n][!CountryCodeConsolidated, \n  on = c(\"country\" = \"country.name.en\",\"year\")] |>\n  (\\(x) data.table(`Missing Rows` = nrow(x)))() |>\n  style_table()\n\n\n\nMissing Rows0\n\n\nGreat, now we can use CountryCodeConsolidated to identify which code source match better with the ccode.\n\nCountryCodeConsolidated[, melt(.SD, id.vars = c(\"country.name.en\",\"ccode\"),\n                               variable.name = \"Country Code Source\", \n                               value.name = \"possible_code\",\n                               variable.factor = FALSE, na.rm = TRUE),\n                        .SDcols = !patterns(\"^(year|country\\\\.name\\\\.en\\\\.regex)$\")\n][, unique(.SD)\n][, .(`% Found` = mean(ccode == possible_code, na.rm = TRUE) |> percent(accuracy = 0.01),\n      `Number of Countries` = uniqueN(country.name.en)),\n  by = \"Country Code Source\"\n][order(-`% Found`,-`Country Code Source`)\n][1:8, style_table(.SD)]\n\n\n\nCountry Code Source% FoundNumber of Countriesp5n96.53%166p4n96.53%166cown95.21%164gwn95.15%163wvs0.00%155vdem0.00%164unpd0.00%160un.regionsub.code0.00%160\n\n\nAs we can see in the table above the country code source with more matching codes is the Polity V Project which monitor regime change and study the effects of regime authority worldwide. This open the door to add more features to our main data, but first it is important to understand why some the p4n didn’t match with the original ccode.\nThe first group is the one that has a p4n the value but it is different to the ccode during some years, as you can see bellow. We will correct the ccode in those cases during this project.\n\nCountryCodeConsolidated[p5n != ccode,\n                  .(start_year = min(year),\n                    end_year = max(year)),\n                  by = c(\"country.name.en\",\"ccode\",\"p5n\")] |>\n  style_table()\n\n\n\ncountry.name.enccodep5nstart_yearend_yearGermany2552601,9901,990Yugoslavia3453471,9921,992Ethiopia5305291,9942,015Sudan6256262,0122,018Yemen6786792,0162,018Vietnam8168181,9902,018\n\n\nThe second group correspond to the years when the bellow countries didn’t have a p5n assign, so we will remand the code that was given by ccode.\n\nCountryCodeConsolidated[is.na(p5n),\n                        .(p5n = unique(p5n),\n                          start_year = min(year),\n                          end_year = max(year)),\n                        by = c(\"country.name.en\",\"ccode\")\n  ][1:8] |>\n  style_table()\n\n\n\ncountry.name.enccodep5nstart_yearend_yearCanada202,0192,020Cuba402,0192,020Haiti412,0192,020Dominican Republic422,0192,020Jamaica512,0192,020Mexico702,0192,020Guatemala902,0192,020Honduras912,0192,020\n\n\n\nregion classifies countries in 8 regions: North America, Central America, South America, Europe, Africa, MENA, Asia and Oceania.\nlocation identifies in which cites the protest took place. Even though the data it’s very messy we might extract some useful information from it.\n\n\n  ProtestRaw[country == \"United Kingdom\", .N,\n             .(country, location)\n  ][order(-N)\n  ][location %like% \",|Edinburgh\"\n  ][1:5] |>\n    style_table()\n\n\n\ncountrylocationNUnited KingdomEdinburgh38United KingdomLondon, London Region3United KingdomDowning Street, London3United KingdomBristol, Norwich, Birmingham, Reading, Bradford, Gillingham, Worcester, Weston super Mare, Sandwell, Greenich, Southamption, Tower Hamlets, Bexley, Southwark1United KingdomSouthampton, Plymouth, Newbury, Leeds, London, Newham, Walton on Thames, Elmbridge, Liecester, Bexley, Catford1\n\n\n\nprotest shows 1 when the row is related to a protest and 0 otherwise.\nyear, startyear, startmonth and startday define when each protest took place.\n\n\n  ProtestRaw[, .(`% of year equals to startyear` = \n                   mean(year == startyear, na.rm = TRUE)|> percent())] |>\n    style_table() |>\n    align(j = 1, align = \"center\")\n\n\n\n% of year equals to startyear100%\n\n\n\nendyear, endmonth and endday defines when each protest ended.\nprotestnumber counts the number of protests that have occurred during a year in a particular country, but the next table shows the exception to the rule.\n\nCambodia in 2003 is missing the first protestnumber\nCambodia in 2004 is missing the second protestnumber\nYugoslavia in 1992 is duplicating the first protestnumber\n\n\nAs we can not ask any one why that happen we will assume that this was a collection problem and we can correct them during the cleaning process.\n\n  ProtestRaw[order(country,year,startmonth,startday), \n             .(startmonth, startday, id, protestnumber ,\n               protest_num_check = max(protestnumber) != uniqueN(id) & \n                                   sum(protest) != 0),\n             by = c(\"country\",\"year\")\n  ][protest_num_check == TRUE, !c(\"protest_num_check\")\n  ][1:7\n  ][, c(\"id\",\"year\") := lapply(.SD,as.character), \n    .SDcols = c(\"id\",\"year\")] |>\n    style_table()\n\n\n\ncountryyearstartmonthstartdayidprotestnumberCambodia20036981120030022Cambodia200372081120030033Cambodia200412581120040011Cambodia2004111381120040033Yugoslavia199222334719920011Yugoslavia199222334719920022Yugoslavia19923234519920011\n\n\n\nprotesterviolence shows 1 when there was violence in the protester side and 0 otherwise.\nparticipants has 771 unique values and estimate the number of participants that were part of each protest. As you can see this column needs a lot of cleaning to be useful.\n\n\n  ProtestRaw[, .N, participants\n  ][c(1:3,(length(N)-3):length(N))] |>\n    style_table()\n\n\n\nparticipantsN1000s1,1871000978500272More than 500,000 people1More than 1,0001About 1000015591\n\n\n\nparticipants_category has 6 categories to define the number of participants that participated in the protest. Then we will try to complete the missing values using the participants column.\n\n\nProtestRaw[, .N, participants_category]|>\n  style_table()\n\n\n\nparticipants_categoryN7,25850-992,508100-9993,2042000-49991,5801000-19994835000-10000642>100001,470\n\n\n\nprotesteridentity has information about the people who protest but some times has information about the protest itself as we can see in the next table.\n\n\n  ProtestRaw[, .N, protesteridentity\n  ][order(-N)\n  ][c(2:4,(length(N)-3):length(N))] |>\n  style_table()\n\n\n\nprotesteridentityNprotesters1,541students646workers273o neill supporters1trade unionists, civil society groups, students and former soldiers1protesters opposed to renewing the licence of a controversial mining company1protesters opposed to counting irregularities during the png parliament elections1\n\n\n\nThe 4 protesterdemand columns have 7 categories to define protesters’ requests.\n\n\n  ProtestRaw[, .SD, .SDcols = patterns(\"^id$|^protesterdemand\")\n  ][, melt(.SD, id.vars = \"id\" , value.name = \"Protester Demand\")\n  ][`Protester Demand` %like% \"\\\\w\",\n    .(`Number of Protests` = uniqueN(id)), \n    by = \"Protester Demand\"\n  ][order(-`Number of Protests`)] |>\n    style_table()\n\n\n\nProtester DemandNumber of Protestspolitical behavior, process10,750labor wage dispute2,211removal of politician1,889price increases, tax policy1,414police brutality1,101social restrictions684land farm issue582\n\n\n\nThe 7 stateresponse columns have 7 categories to define States’ responses. By checking the table bellow we can see that accommodation was misspelled as accomodation which also the attribute that we want to understand.\n\n\n  ProtestRaw[, .SD, .SDcols = patterns(\"^id$|^stateresponse\")\n  ][, melt(.SD, id.vars = \"id\", value.name = \"State Response\")\n  ][`State Response` %like% \"\\\\w\",\n    .(`Number of Protests` = uniqueN(id)), \n    by = \"State Response\"\n  ][order(-`Number of Protests`)] |>\n    style_table()\n\n\n\nState ResponseNumber of Protestsignore8,285crowd dispersal4,772arrests2,149accomodation1,527shootings936killings828beatings803\n\n\n\nnotes has a paragraph that describes each protest. The average number of words for each paragraph is 98 words which is higher than median so there are some outliers with very long paragraphs.\n\n\nProtestRaw[notes %like% \"\\\\w\", \n           .(id, `Number of words` = str_squish(notes) |> str_count(\" \")+1)\n          ][, word_avg := mean(`Number of words`)] |>\n  ggplot(aes(`Number of words`))+\n  geom_histogram(bins = 30, fill = \"dodgerblue3\")+\n  geom_vline(aes(xintercept = word_avg))+\n  scale_x_log10()+\n  labs(title = \"Distribution of number of words per note\")\n\n\n\n\n\nsources has a paragraph that describes where the is information is coming from. The average number of words for each paragraph is 34 words which is higher than median so there are some outliers with very long paragraphs.\n\n\nProtestRaw[sources %like% \"\\\\w\", \n           .(id, `Number of words` = str_squish(sources) |> str_count(\" \")+1)\n          ][, word_avg := mean(`Number of words`)] |>\n  ggplot(aes(`Number of words`))+\n  geom_histogram(bins = 30, fill = \"dodgerblue3\")+\n  geom_vline(aes(xintercept = word_avg))+\n  scale_x_log10()+\n  labs(title = \"Distribution of number of words per source\")"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#missing-data-distribution",
    "href": "projs/mass-protest-data/main.html#missing-data-distribution",
    "title": "Characteristics of Successful Protests",
    "section": "2.2 Missing data distribution",
    "text": "2.2 Missing data distribution\nIt is important to know that the data has 17,145 rows, but not all rows represent a protest, 1,906 rows of the data represent years where the wasn’t any protest in a particular country. Let’s see how is the missing value distribution in each case.\n\nProtestRaw[, lapply(.SD, function(x) x |> is.na() |> mean()),\n    by = .(protest = fifelse(protest>0,\"Protest\",\"No Protest\"))\n  ][, melt(.SD, id.vars = \"protest\", \n           variable.name = \"Variables\",\n           value.name = \"# Missing\")\n  ][, Variables := fct_reorder(Variables, `# Missing`, sum)] |>\n  ggplot(aes(`# Missing`, `Variables`))+\n  geom_blank(aes(x = `# Missing` *1.1))+\n  geom_col(fill = \"dodgerblue3\")+\n  geom_text(aes(label = percent(`# Missing`, accuracy = 0.01)),\n            hjust = -0.3)+\n  scale_x_continuous(labels = percent_format(accuracy = 1))+\n  facet_wrap(~protest)+\n  labs(title = \"Proportions of missing values per variable\",\n       x = \"% Of Missing Values\")\n\n\n\n\nAs we can check the rows that doesn’t represent a protest are very empty. We will remove them as they won’t be useful to answer the question."
  },
  {
    "objectID": "projs/mass-protest-data/main.html#initial-cleaning",
    "href": "projs/mass-protest-data/main.html#initial-cleaning",
    "title": "Characteristics of Successful Protests",
    "section": "3.1 Initial cleaning",
    "text": "3.1 Initial cleaning\nIn this section we will apply simplest cleaning steps at once.\n\nProtestSimpleClean <-\n  \n  # Fixing wrong ccodes\n  CountryCodeConsolidated[, .(country = country.name.en, year, p4n)\n  ][, unique(.SD)\n  ][ProtestRaw, on = c(\"country\",\"year\")\n  ][ccode != p4n, ccode := p4n\n  ][, !c(\"p4n\")\n    \n  # Taking out rows that aren't related to a protest\n  ][protest == 1, !c(\"protest\")\n        \n  # Transforming start and end dates to a date format\n  ][, `:=`(start_date =  \n             paste(startyear,startmonth,startday,sep = \"-\") |> ymd(),\n           end_date =  \n             paste(endyear,endmonth,endday,sep = \"-\") |> ymd())\n  ][order(start_date), \n    .SD, .SDcols = !patterns(\"\\\\w+year$|\\\\w+month$|\\\\w+day$\")\n   \n  # Correcting the protestnumber of each year and country\n  ][, protestnumber := 1:.N,\n    by = c(\"country\",\"year\")\n    \n  # Setting Country and Location Case\n  ][,`:=`(location = lower_clean_name(location) |> \n                     str_replace_all(\"kiev\",\"kyiv\") |>\n                     str_replace_all(\"chittagong\",\"chattogram\"),\n          country = lower_clean_name(country)) ]"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#completing-participants_category-with-participants-column",
    "href": "projs/mass-protest-data/main.html#completing-participants_category-with-participants-column",
    "title": "Characteristics of Successful Protests",
    "section": "3.2 Completing participants_category with participants column",
    "text": "3.2 Completing participants_category with participants column\nAs the participants column contains aproximations related to number of people who took place during each protests makes more same to complete the missing participants_category based on those approximations by using the next code.\n\nProtestCategoryClean <-\n  \n  # Let's work only with protests that are missing participants_category\n  ProtestSimpleClean[is.na(participants_category)\n                     \n  # Applying general cleaning to participants\n  ][,participants := participants |>  \n                      str_to_lower() |> \n                      str_remove_all(\",\") |>\n                      str_squish()\n    \n  # Getting the average of participants intervals\n  ][, c(\"min\",\"max\") := tstrsplit(participants,\"-| to \", fixed = FALSE)\n  ][participants %like% \"between \\\\d+ and \\\\d+\", \n    `:=`(min = str_match(participants, \"between (\\\\d+) and \\\\d+\")[,2],\n         max = str_match(participants, \"between \\\\d+ and (\\\\d+)\")[,2])\n  ][, c(\"min\",\"max\") := lapply(.(min, max), \n                               \\(x) str_extract(x, \"\\\\d+\") |> as.double())\n  ][, `:=`(participants_clean = (min+max)/2,\n           min = NULL,\n           max = NULL)\n    \n  # Getting number of protesters by using regular expressions\n  ][participants %like% \"^\\\\d+$\" & is.na(participants_clean),\n    participants_clean := \n      as.double(participants)\n  ][participants %like% \"^\\\\d+\\\\+$\" & is.na(participants_clean),\n    participants_clean := \n      str_remove_all(participants,\"\\\\+\") |> \n      as.double()\n  ][participants %like% \"^\\\\d+s\" & is.na(participants_clean),\n    participants_clean :=\n      str_match(participants,\"^(\\\\d+)s\")[,2] |>  \n      as.double()\n  ][participants %like% \"^[><]\\\\d+\" & is.na(participants_clean),\n    participants_clean := \n      str_match(participants,\"^[><](\\\\d+)\")[,2] |>\n      as.double()\n    \n  # Getting number of protesters by reading the notes variable\n  ][id == 922006004, \n    participants_clean := 50\n  ][id == 6602002005, \n    participants_clean := 2000\n    \n  # Creating a new participants_category variable\n  ][, `:=`(participants_category = \n             fcase( between(participants_clean, 1, 99), \"1-99\",\n                    between(participants_clean, 100, 999), \"100-999\",\n                    between(participants_clean, 1000, 1999), \"1000-1999\",\n                    between(participants_clean, 2000, 4999), \"2000-4999\",\n                    between(participants_clean, 5000, 10000), \"5000-10000\",\n                    participants_clean > 10000, \">10000\"),\n           participants_clean = NULL)\n    \n  # Adding protests that aren't missing participants_category  \n  ][, rbind(.SD,\n            ProtestSimpleClean[!is.na(participants_category)])\n    \n  # Making participants_category a factor variable \n  # to make easier to plot the data later\n  ][participants_category == \"50-99\",\n    participants_category := \"1-99\"\n  ][, `:=`(participants_category = factor(participants_category,\n                                          levels = c(\"Missing\",   \"1-99\",     \n                                                     \"100-999\",   \"1000-1999\", \n                                                     \"2000-4999\", \"5000-10000\",\n                                                     \">10000\")),\n           participants = NULL)]\n\n\n  ProtestCategoryClean[, .N, participants_category] |>\n    style_table()\n\n\n\nparticipants_categoryN1-993,3031000-19991,608>100002,121100-9994,9175000-100001,2602000-49992,01911\n\n\nThere 11 protests where the wasn’t any information about the number of participants and label them as Missing."
  },
  {
    "objectID": "projs/mass-protest-data/main.html#reshaping-protesterdemand-and-stateresponse",
    "href": "projs/mass-protest-data/main.html#reshaping-protesterdemand-and-stateresponse",
    "title": "Characteristics of Successful Protests",
    "section": "3.3 Reshaping protesterdemand and stateresponse",
    "text": "3.3 Reshaping protesterdemand and stateresponse\nNow we reorganize the protesterdemand and stateresponse to have a single column for each category having 1 if the each category is related to the protest and 0 otherwise.\n\nProtestReshaped <-\n  \n  # Melting protesterdemand and stateresponse just keeping protest id\n  ProtestCategoryClean[, melt(.SD, id.vars = \"id\",\n                              measure.vars =\n                                str_subset(names(.SD),\n                                           \"^(protesterdemand|stateresponse)\"),\n                              value.name = \"actions\",\n                              variable.factor = FALSE)\n  ][actions %like% \"\\\\w\"\n  ][,`:=`(variable = fifelse(variable %like% \"^protesterdemand\", \n                             \"dem\",\"res\"),\n          actions = fifelse(actions == \"accomodation\",\n                            \"accommodation\",actions),\n          action_occur = TRUE)\n  ][, unique(.SD) \n  ][, dcast(.SD, id ~ variable + actions, \n            value.var = \"action_occur\", fill = FALSE)\n    \n    \n  # Adding the other variables to have back the data complete\n  ][, merge(.SD, \n            ProtestCategoryClean, \n            by = \"id\", all = TRUE)\n  ][, .SD, \n    .SDcols = !patterns(\"^(protesterdemand|stateresponse)\")\n  ][,{ \n    ColsToFill <- str_subset(names(.SD),\"^(dem|res)\")\n    copy(.SD)[is.na(res_shootings), (ColsToFill) := FALSE]\n  }][, protesterviolence := protesterviolence == 1]\n\nAfter applying those changes we can see that currently all the columns have less than 5% of missing values.\n\nProtestReshaped[, lapply(.SD, function(x) mean(is.na(x)))\n  ][, id := 1\n  ][, melt(.SD, id.vars = \"id\", \n           variable.name = \"Variables\",\n           value.name = \"# Missing\")\n  ][, `:=`(Variables = fct_reorder(Variables, `# Missing`, sum))] |>\n  ggplot(aes(`# Missing`, `Variables`))+\n  geom_blank(aes(x = `# Missing` *1.15))+\n  geom_col(fill = \"dodgerblue3\")+\n  geom_text(aes(label = percent(`# Missing`, accuracy = 0.01)), hjust = -0.3)+\n  scale_x_continuous(labels = percent_format(accuracy = 0.01))+\n  expand_limits(x = 1)+\n  labs(title = \"Proportions of missing\\nvalues per variable\",\n       x = \"% Of Missing Values\")"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#joining-policatical-situation",
    "href": "projs/mass-protest-data/main.html#joining-policatical-situation",
    "title": "Characteristics of Successful Protests",
    "section": "3.4 Joining policatical situation",
    "text": "3.4 Joining policatical situation\nAs we already confirmed that the data is related to Center for Systemic Peace data adding the variables to the main data can be done in one line of code.\n\nProtestPolitical <-\n  Polity5[ProtestReshaped, on = c(\"ccode\",\"year\")]"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#extracting-location-data",
    "href": "projs/mass-protest-data/main.html#extracting-location-data",
    "title": "Characteristics of Successful Protests",
    "section": "3.5 Extracting location data",
    "text": "3.5 Extracting location data\nAs we know in the column location there is information about the place where each protests took place. I would be really interesting to extract from that field the following information:\n\nDoes it mention if it was a national protest?\nHow many cities mention each protest?\nDid the protest took place in the capital?\n\nTo achieve that we need to make the process in 3 steps.\n\nIn the first step we need check in the location field mention if the protest took place nationality and identify the cities that have a perfect math with the WorldCities data frame.\n\n\nNationalRegex <-\n  \"nationwide|(^| )national( level| including| in scope|.+cities|$|[:;,\\\\.])|across (.*country|\"\n\nCustomStopWords <-\n  c(stop_words$word, tm::stopwords(\"spanish\"), \"region\",\n    \"province\", \"district\", \"valley\", \"including\",\"cities\",\n    \"shire\", \"downtown\", \"national\", \"parliament\")\n\nProtestExactCityMatch <-\n  WorldCities[, .(city_regex = str_c(city_ascii,collapse = \"|\")),\n              by = \"country\"\n  ][ProtestPolitical, on = \"country\"\n  ][, `:=`(exact_cities_found = .(str_extract_all(location, city_regex) |> \n                                    unlist() |> \n                                    unique()),\n           is_national = location %like% str_c(NationalRegex, country,\")\"),\n           location_no_found = str_remove_all(location, city_regex) |>\n                               str_remove_all(str_c(NationalRegex, country,\")\")) |>\n                               str_squish()),\n    by = \"id\"\n  ][,`:=`(num_cities = sapply(exact_cities_found, length),\n          city_regex = NULL)\n  ][!location_no_found %like% \"\\\\w\" |\n      location_no_found %chin% CustomStopWords,\n    location_no_found := NA_character_]\n\nAfter extracting all matching cities and checking if the location field identified each protest as a national one we saved the remaining words in the variable location_no_found for further analysis.\n\nAssuming the in many cases of location_no_found the remaining words just make reference to one city we can compare all the cities of each country and take the city that minimize the LCS (longest common sub-string distance) measure from the stringdist package.\n\n\nStringApproxCols <- \n  c(\"id\", \"country\", \"location\", \"location_no_found\", \"num_cities\")\n\nOneWorldCityApprox <-\n  ProtestExactCityMatch[!is.na(location_no_found), ..StringApproxCols] |>\n  find_string_approximation(DT2 = WorldCities[,.(country, city_ascii)],\n                            id.var = \"id\",\n                            merge.by = \"country\",\n                            match.vars = c(\"location_no_found\",\"city_ascii\")) |>\n  setnames(\"location_no_found\",\"city_word\")\n\nAt the end, we could find 897 protest cities. but that with that we can find cities if the field describes more than one city. To check that let’s see the number of words distribution.\n\nplot_word_found_distribution(ProtestExactCityMatch,\n                             word.count.var = \"location_no_found\",\n                             prostest.id.found = OneWorldCityApprox$id,\n                             success.label = \"City found\",\n                             no.found.label = \"City no found\",\n                             label.colors = c(\"City found\" = \"dodgerblue3\",\n                                              \"City no found\" = \"brown2\"),\n                             subtitle = \"After applying one city approximation match\")\n\n\n\n\nAs we can see most of the cities found only have one of two words and only some few one have 3 or 4 words. It is all also important to check that rows with one word didn’t find any city related so we can take those cases out as we won’t any extra city related those cases.\n\nManyWorldCityApprox <-\n  lapply(1:4, function(n_gram){\n  ProtestExactCityMatch[!is.na(location_no_found) &\n                          str_count(location_no_found,\" \") >= 1 &\n                          !id %in% OneWorldCityApprox$id,\n                        unnest_tokens(.SD, city_word,location_no_found,\n                                      token = \"ngrams\", n = n_gram),\n                        .SDcols = StringApproxCols\n  ][! city_word %chin% CustomStopWords,\n    find_string_approximation(.SD,\n                              DT2 = WorldCities[,.(country, city_ascii)],\n                              id.var = \"id\",\n                              merge.by = \"country\",\n                              match.vars = c(\"city_word\",\"city_ascii\"))\n  ][, n_gram := n_gram]}) |>\n  rbindlist() \n\nIn next chart we can see how we could find cities in very long text with more than 20 words by applying string distance approximation.\n\nplot_word_found_distribution(ProtestExactCityMatch,\n                             word.count.var = \"location_no_found\",\n                             prostest.id.found = c(OneWorldCityApprox$id,\n                                                   ManyWorldCityApprox$id),\n                             success.label = \"City found\",\n                             no.found.label = \"City no found\",\n                             label.colors = c(\"City found\" = \"dodgerblue3\",\n                                              \"City no found\" = \"brown2\"),\n                             subtitle = \"After applying many city approximation match\")\n\n\n\n\nNow it’s time to add the cities found to the main data.\n\nProtestLocationExtracted <-\n  list(OneWorldCityApprox[, c(\"id\",\"country\",\"city_ascii\")],\n       ManyWorldCityApprox[, c(\"id\",\"country\",\"city_ascii\")],\n       ProtestExactCityMatch[, .(city_ascii = exact_cities_found[[1]]),\n                             by = c(\"id\",\"country\")]) |>\n  rbindlist() |>\n  unique() |>\n  merge(WorldCities,\n        by = c(\"country\",\"city_ascii\"), all.x = TRUE) |>\n  (\\(DT) DT[, .(cities_found = .(city_ascii),\n                num_cities = .N,\n                in_capital = sum(capital == \"primary\",na.rm = TRUE) > 0,\n                total_population = sum(population, na.rm = TRUE)),\n            by = \"id\"\n         ][ProtestExactCityMatch[,!c(\"exact_cities_found\",\n                                     \"num_cities\",\n                                     \"location_no_found\",\n                                     \"location\")],\n           on = \"id\"\n         ][is.na(num_cities), \n           `:=`(num_cities = 0,\n                in_capital = FALSE)])()"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#final-result",
    "href": "projs/mass-protest-data/main.html#final-result",
    "title": "Characteristics of Successful Protests",
    "section": "3.6 Final Result",
    "text": "3.6 Final Result\nAfter applying many transformations to the data we are ready to explore it. The new data it is tidy format and we will easy to manipulate across the exploration process.\n\nglimpse(ProtestLocationExtracted)\n\nRows: 15,239\nColumns: 37\n$ id                                <dbl> 201990001, 201990002, 201990003, 201…\n$ cities_found                      <list> <NULL>, <\"montreal\", \"quebec city\">…\n$ num_cities                        <int> 0, 2, 2, 2, 2, 2, 0, 0, 1, 1, 0, 1, …\n$ in_capital                        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ total_population                  <dbl> NA, 4224698, 4224698, 4224698, 42246…\n$ country                           <chr> \"canada\", \"canada\", \"canada\", \"canad…\n$ ccode                             <int> 20, 20, 20, 20, 20, 20, 20, 20, 20, …\n$ year                              <int> 1990, 1990, 1990, 1990, 1990, 1990, …\n$ democ                             <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n$ autoc                             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ polity                            <dbl> 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n$ durable                           <int> 102, 102, 102, 102, 102, 102, 103, 1…\n$ government_status                 <chr> \"Active\", \"Active\", \"Active\", \"Activ…\n$ `dem_labor wage dispute`          <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FA…\n$ `dem_land farm issue`             <lgl> FALSE, FALSE, FALSE, TRUE, FALSE, FA…\n$ `dem_police brutality`            <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, T…\n$ `dem_political behavior, process` <lgl> TRUE, TRUE, TRUE, FALSE, TRUE, FALSE…\n$ `dem_price increases, tax policy` <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ `dem_removal of politician`       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ `dem_social restrictions`         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ res_accommodation                 <lgl> FALSE, FALSE, FALSE, TRUE, TRUE, FAL…\n$ res_arrests                       <lgl> FALSE, FALSE, FALSE, FALSE, TRUE, FA…\n$ res_beatings                      <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ `res_crowd dispersal`             <lgl> FALSE, FALSE, FALSE, FALSE, TRUE, TR…\n$ res_ignore                        <lgl> TRUE, TRUE, TRUE, FALSE, FALSE, FALS…\n$ res_killings                      <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ res_shootings                     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, T…\n$ region                            <chr> \"North America\", \"North America\", \"N…\n$ protestnumber                     <int> 1, 2, 3, 4, 5, 6, 1, 2, 1, 1, 2, 1, …\n$ protesterviolence                 <lgl> FALSE, FALSE, FALSE, TRUE, TRUE, FAL…\n$ participants_category             <fct> 1000-1999, 1000-1999, 100-999, 100-9…\n$ protesteridentity                 <chr> \"unspecified\", \"unspecified\", \"separ…\n$ sources                           <chr> \"1. great canadian train journeys in…\n$ notes                             <chr> \"canada s railway passenger system w…\n$ start_date                        <date> 1990-01-15, 1990-06-25, 1990-07-01,…\n$ end_date                          <date> 1990-01-15, 1990-06-25, 1990-07-01,…\n$ is_national                       <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FA…"
  },
  {
    "objectID": "projs/mass-protest-data/main.html#exploring-numeric-correlations",
    "href": "projs/mass-protest-data/main.html#exploring-numeric-correlations",
    "title": "Characteristics of Successful Protests",
    "section": "4.1 Exploring numeric correlations",
    "text": "4.1 Exploring numeric correlations\nThe first step it’s to take out variables that don’t bring big insights and case of finding any relation, then we select logical and numeric variables and calculate correlations for all numeric and logical variables.\n\nCorSummary <-\n  ProtestLocationExtracted[, !c(\"id\",\"ccode\",\"democ\",\"autoc\", \"durable\")\n  ][, participants_category := as.integer(participants_category)\n  ][, lapply(.SD, \\(x) x * 1),\n    .SDcols = \\(x) is.logical(x) | is.numeric(x)] |> \n  correlation() |>\n  as.data.table()\n\nCorSummary[1:6,\n           lapply(.SD, \\(x) if(is.numeric(x)){round(x,2)}else{x}),\n           .SDcols = !patterns(\"^(t|df_error)$\")] |>\n  style_table()\n\n\n\nParameter1Parameter2rCICI_lowCI_highpMethodn_Obsnum_citiesin_capital0.260.950.240.270.00Pearson correlation15,239num_citiestotal_population0.150.950.130.170.00Pearson correlation13,029num_citiesyear0.040.950.020.050.00Pearson correlation15,239num_citiespolity0.000.95-0.020.011.00Pearson correlation13,804num_citiesdem_labor wage dispute-0.030.95-0.05-0.020.00Pearson correlation15,239num_citiesdem_land farm issue-0.020.95-0.04-0.010.22Pearson correlation15,239\n\n\nAs we have many significant correlations, let’s center our attention in higher significan ones\n\nset.seed(110)\nCorSummary[p < 0.05 & abs(r) >= 0.10] |>\n  graph_from_data_frame(directed = FALSE) |>\n  ggraph(layout = \"with_dh\")+\n  geom_edge_link(aes(edge_color = r), \n                 edge_width = 1)+\n  geom_node_point(size = 3)+\n  geom_node_text(aes(label = name), repel = TRUE)+\n  scale_edge_color_gradient2(low = \"red\", high = \"blue\")+\n  labs(title = \"Correlation Network\")\n\n\n\n\nBy checking the last graph, we can see some interesting relations:\n\nIf protesters present violence during the manifestation it is more probable that the state responds with shootings, killings, beatings and arrests in countries with low democracy (polity) other wise it’s more common for states to ignore the protests and crowd dispersal is independent from polity levels.\nLabor wage disputes takes place nationally in democratic countries with a low change of sharing the protest purpose demanding police brutality reduction.\nRemoval a politician usually takes place in the capital of countries with low polity with many participants several times a in a year.\nWhen a protest is demanding a political behavior it’s weird to see that protesters want other demands.\n\nLet’s confirm those findings adding other charts to see with extra details of each relation.\n\n4.1.1 Distribution\n\nAdding Confident Intervals\nAdding text to identify each side meaning\n\n\nProtestLocationExtracted[!is.na(polity), \n                         melt(.SD, id.vars = c(\"id\",\"polity\",\"protesterviolence\"),\n                              value.name = \"Happen\",\n                              variable.name = \"Response\",na.rm = TRUE), \n                         .SDcols = patterns(\"^(id|polity|protesterviolence)$|^res\")\n][, .(occurrence_prop = mean(Happen)),\n  by = .(`Protester Violence` = protesterviolence,\n         Polity = fifelse(polity <= 4, \"Low Democracy\", \"High Democracy\"),\n         Response = sub(\"^res_\",\"\",Response) |> str_to_title())\n][, dcast(.SD, ... ~ Polity, value.var = \"occurrence_prop\")\n][, `occurrence_prop_high/low_democracy` := log2(`High Democracy`/`Low Democracy`)\n][, Response := fct_reorder(Response, `occurrence_prop_high/low_democracy`, sum)] |>\n  ggplot(aes(`occurrence_prop_high/low_democracy`, Response, color = `Protester Violence`))+\n  geom_point(size = 4)+\n  geom_vline(aes(xintercept = 0), size = 1)+\n  scale_x_continuous(breaks = breaks_width(0.5))+\n  scale_color_manual(values = c(\"FALSE\" = \"dodgerblue3\", \"TRUE\" = \"brown2\"))+\n  labs(title = \"State Response Exploration\",\n       y = \"State Response\", \n       x = \"Log of Odds Ratio:\\nResponse Occurrence Between High/Low Democratic Countries\")+\n  theme(panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        legend.position = \"top\")\n\n\n\n\nFor example, when states response with killings the 75% percent of protests were violent.\n\n\n\nArel-Bundock, Vincent, Nils Enevoldsen, and CJ Yetman, (2018). countrycode: An R package to convert country names and country codes. Journal of Open Source Software, 3(28), 848, https://doi.org/10.21105/joss.00848\nhttps://www.systemicpeace.org/inscrdata.html (Center for Systemic Peace)\nhttps://simplemaps.com/data/world-cities"
  }
]